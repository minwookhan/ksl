* Optical Flow 설명
:PROPERTIES:
:ID:       3e43cf43-c0b8-4986-a449-64f2e076ed6a
:END:

**Optical Flow(광학 흐름)**는 영상 내에서 물체의 움직임 패턴을 추적하여 **"얼마나, 어느 방향으로 움직였는가"**를 수치화하는 기술입니다.
`ksl-cli` 프로젝트에서 Optical Flow는 **"수어 동작이 멈추는 순간(Stabilization)"**을 포착하여 깨끗한 이미지를 서버로 보내기 위해 사용됩니다.
상세한 작동 원리와 코드상의 구현 내용을 단계별로 설명해 드리겠습니다.
** 1. Optical Flow의 역할 (Why?)
수어는 손을 움직이는 **동작(Motion)**과 동작이 끝난 후 보여주는 **형태(Pose)**로 이루어집니다.
- **움직이는 중**: 손이 빠르게 이동하므로 카메라 영상에서 **블러(Motion Blur)**가 발생하고, 정확한 손 모양 인식이 어렵습니다.
- **멈춘 순간**: 동작이 완료되어 손 모양이 선명합 니다. 이때가 인공지능이 인식하기 가장 좋은 타이밍(**Keyframe**)입니다.

이 프로젝트에서 Optical Flow는 **"화면의 움직임이 임계값 이하로 떨어졌는가?"**를 판단하여, 움직임이 멈춘 선명한 프레임을 골라내는 **필터 역할**을 합니다.
** 2. 상세 알고리즘: Lucas-Kanade (LK) 기법
이 코드는 모든 픽셀을 계산하는 방식(Dense)이 아니라, 추적하기 쉬운 몇 개의 점만 골라서 추적하는 **희소(Sparse) Optical Flow** 방식인 **Lucas-Kanade** 알고리즘을 사용합니다.

*** 1단계: 추적할 점 찾기 (Feature Detection)
- **함수**: `cv2.goodFeaturesToTrack`
- **원리**: 아무 점이나 추적하지 않습니다. 흰 벽이나 파란 하늘 같은 평평한 곳은 움직임을 알기 어렵습니다. 따라서 **모서리(Corner)**나 **엣지(Edge)**처럼 뚜렷한 특징이 있는 점들을 먼저 찾습니다.
- **코드**: `prev_gray` 이미지에서 `maxCorners=300`개의 특징점을 찾습니다.

*** 2단계: 점의 이동 위치 계산 (Tracking)
- **함수**: `cv2.calcOpticalFlowPyrLK`
- **원리**:
  - 이전 프레임(`prev_gray`)에서 찾은 점들이 현재 프레임(`curr_gray`)에서 어디로 이동했는지 찾습니다.
  - **피라미드(Pyramid) 기법**: 이미지를 단계적으로 축소해서 큰 움직임부터 작은 움직임까지 놓치지 않고 추적합니다.
- **결과**: 점들의 새로운 좌표(`p1`)를 얻습니다.

*** 3단계: 이동 거리(속도) 계산 (Magnitude Calculation)
- **로직**:
  $$ \text{이동 거리} = \sqrt{(x_{new} - x_{old})^2 + (y_{new} - y_{old})^2} $$
- **구현**: `np.linalg.norm(good_new - good_old, axis=1)`
- 추적된 모든 점들이 이동한 거리의 **평균값(`avg_motion`)**을 구합니다.

** 3. 코드와 데이터 흐름 분석 (`src/video.py`)

이 과정은 `VideoLoader`에서 리사이징된 **320x180 흑백 이미지**를 사용하여 매우 빠르게 수행됩니다.

#+BEGIN_SRC python
def calculate_optical_flow_value(prev_gray, curr_gray):
    # 1. 특징점 추출 (Shi-Tomasi Corner Detector)
    # 이전 프레임에서 추적하기 좋은 '모서리' 점들을 찾음
    p0 = cv2.goodFeaturesToTrack(prev_gray, mask=None, **feature_params)

    # 특징점이 없으면 움직임 0으로 간주
    if p0 is None: return 0.0

    # 2. 루카스-카나데(Lucas-Kanade) Optical Flow 계산
    # 이전 프레임의 점(p0)들이 현재 프레임(curr_gray)에서 어디(p1)로 갔는지 계산
    p1, st, err = cv2.calcOpticalFlowPyrLK(prev_gray, curr_gray, p0, None, **lk_params)

    if p1 is not None:
        # 유효하게 추적된 점들만 필터링 (st==1)
        good_new = p1[st == 1]
        good_old = p0[st == 1]

        # 3. 이동 벡터의 크기(Euclidean Distance) 계산
        displacements = np.linalg.norm(good_new - good_old, axis=1)

        # 4. 전체 움직임의 평균값 반환
        return float(np.mean(displacements))
#+END_SRC

** 4. 핵심 요약
1. **입력**: 이전 프레임(Gray), 현재 프레임(Gray). (크기: 320x180)
2. **작동**: 특징점(코너)을 찾고 → 다음 프레임에서 위치를 추적 → 이동 거리를 잰다.
3. **출력**: **`avg_motion` (실수형 숫자 하나)**.
   - 값이 **크면**: 사람이 활발하게 움직이는 중 (전송 X).
   - 값이 **작으면**: 동작을 멈추고 포즈를 취함 (전송 O).

이 값은 `main.py`에서 `avg_motion < OPTICAL_FLOW_THRESH` (기본값 0.45) 조건문에서 사용되어 **키프레임 전송 시점**을 결정하는 결정적인 트리거가 됩니다.
